{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tikiproject_week1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2KamATylck"
      },
      "source": [
        "import re\n",
        "data = []\n",
        "\n",
        "# request page may pha ca phe\n",
        "!pip install selenium\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install webdriver-manager\n",
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless') \n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')\n",
        "options.add_argument(\"--incognito\")\n",
        "i = 1\n",
        "while True:\n",
        "  driver = webdriver.Chrome('chromedriver',options=options)\n",
        "  driver.implicitly_wait(30)\n",
        "\n",
        "  tiki_url = f'https://tiki.vn/may-pha-ca-phe/c1939?page={i}&src=c.1882.hamburger_menu_fly_out_banner'\n",
        "  print('this is -----------------------------------------------',tiki_url)\n",
        "  driver.get(tiki_url)\n",
        "\n",
        "  html_data = driver.page_source\n",
        "\n",
        "  driver.close()\n",
        "    \n",
        "  # parse html into beautiful soup\n",
        "  from bs4 import BeautifulSoup\n",
        "\n",
        "  # r.text is a HTML file so use html.parser\n",
        "  soup = BeautifulSoup(html_data, 'html.parser')\n",
        "  # total number of items:  \n",
        "  result_items = soup.find('div', {'class':\"CategoryViewstyle__Right-bhstkd-1 jJGphj\"}).div.div.div.h4.text.split()[0]\n",
        "  # scripts of all item in page 1     \n",
        "  scripts = soup.find_all('script', {'type': 'application/ld+json'})\n",
        "\n",
        "  if int(len(data)) >= int(result_items):\n",
        "    break\n",
        "  else:\n",
        "    for a in range(1,len(scripts)-1): \n",
        "      test = str(scripts[a])\n",
        "\n",
        "      # find product_id\n",
        "      pattern = r'.*\"sku\":\"(\\d+)\".*'\n",
        "      product_id1 = str(re.findall(pattern, test)).strip('[')\n",
        "      product_id2 = product_id1.strip(']')\n",
        "      product_id = product_id2.strip(\"'\")\n",
        "\n",
        "      # file title\n",
        "      pattern = r'\"name\":\"(.*)\",\"des'\n",
        "      title1 = str(re.findall(pattern, test)).strip('[')\n",
        "      title2 = title1.strip(']')\n",
        "      title = title2.strip(\"'\")\n",
        "\n",
        "      # find price\n",
        "      pattern = r'\"price\":(\\d+)}'\n",
        "      price1 = str(re.findall(pattern, test)).strip('[')\n",
        "      price2 = price1.strip(']')\n",
        "      price = price2.strip(\"'\")\n",
        "\n",
        "      # find image\n",
        "      pattern = r'\"image\":\"(.*g)\",\"name'\n",
        "      image_url1 = str(re.findall(pattern, test)).strip('[')\n",
        "      image_url2 = image_url1.strip(']')\n",
        "      image_url = image_url2.strip(\"'\")\n",
        "\n",
        "      # find product_url\n",
        "      pattern = r'\"url\":\"(.*)\",\"image\"'\n",
        "      product_url1 = str(re.findall(pattern, test)).strip('[')\n",
        "      product_url2 = product_url1.strip(']')\n",
        "      product_url = product_url2.strip(\"'\")\n",
        "\n",
        "      # create data contain dict of 48 items\n",
        "      d_script = {'product_id':'', 'title':'', 'price':'', 'image_url':'', 'product_url':''}\n",
        "      try:\n",
        "          d_script['product_id'] = product_id\n",
        "          d_script['title'] = title\n",
        "          d_script['price'] = price\n",
        "          d_script['image_url'] = image_url\n",
        "          d_script['product_url'] = product_url\n",
        "          data.append(d_script)\n",
        "\n",
        "      except:\n",
        "          print(\"We got one article error!\")\n",
        "  i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY_VaYXh0GwV"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIX4OFH30MO-"
      },
      "source": [
        "# create dataframe\n",
        "import pandas as pd\n",
        " \n",
        "product = pd.DataFrame(data = data)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQ-RyuZ0Oik"
      },
      "source": [
        "product"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}